{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wav2vec2_vib import Model\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woonj/anaconda3/envs/grad_cam/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Model(\n",
    "    device=device,\n",
    "    ssl_cpkt_path='xlsr2_300m.pt', # https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/xlsr/README.md#:~:text=XLS%2DR%20300M-,download,-XLS%2DR%201B\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('vib_conf-5_gelu_2s_may27_epoch6.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "Model                                                             --\n",
       "├─SSLModel: 1-1                                                   --\n",
       "│    └─Wav2Vec2Model: 2-1                                         1,024\n",
       "│    │    └─ConvFeatureExtractionModel: 3-1                       4,210,176\n",
       "│    │    └─Linear: 3-2                                           525,312\n",
       "│    │    └─Dropout: 3-3                                          --\n",
       "│    │    └─Dropout: 3-4                                          --\n",
       "│    │    └─GumbelVectorQuantizer: 3-5                            574,080\n",
       "│    │    └─Linear: 3-6                                           590,592\n",
       "│    │    └─TransformerEncoder: 3-7                               310,701,184\n",
       "│    │    └─LayerNorm: 3-8                                        1,024\n",
       "│    │    └─Linear: 3-9                                           787,200\n",
       "├─Linear: 1-2                                                     131,200\n",
       "├─BatchNorm2d: 1-3                                                2\n",
       "├─BatchNorm2d: 1-4                                                128\n",
       "├─Dropout: 1-5                                                    --\n",
       "├─SELU: 1-6                                                       --\n",
       "├─CrossEntropyLoss: 1-7                                           --\n",
       "├─VIB: 1-8                                                        --\n",
       "│    └─Sequential: 2-2                                            --\n",
       "│    │    └─Linear: 3-10                                          16,512\n",
       "│    │    └─GELU: 3-11                                            --\n",
       "│    │    └─Dropout: 3-12                                         --\n",
       "│    │    └─Linear: 3-13                                          16,512\n",
       "│    │    └─GELU: 3-14                                            --\n",
       "│    │    └─Dropout: 3-15                                         --\n",
       "│    └─Linear: 2-3                                                8,256\n",
       "│    └─Linear: 2-4                                                8,256\n",
       "│    └─Sequential: 2-5                                            --\n",
       "│    │    └─Linear: 3-16                                          8,320\n",
       "│    │    └─GELU: 3-17                                            --\n",
       "│    │    └─Dropout: 3-18                                         --\n",
       "│    │    └─Linear: 3-19                                          16,512\n",
       "├─BackEnd: 1-9                                                    --\n",
       "│    └─Sequential: 2-6                                            --\n",
       "│    │    └─Linear: 3-20                                          4,160\n",
       "│    │    └─GELU: 3-21                                            --\n",
       "│    │    └─Dropout: 3-22                                         --\n",
       "│    │    └─Linear: 3-23                                          4,160\n",
       "│    │    └─GELU: 3-24                                            --\n",
       "│    │    └─Dropout: 3-25                                         --\n",
       "│    │    └─Linear: 3-26                                          4,160\n",
       "│    │    └─GELU: 3-27                                            --\n",
       "│    │    └─Dropout: 3-28                                         --\n",
       "│    └─Linear: 2-7                                                130\n",
       "├─GELU: 1-10                                                      --\n",
       "==========================================================================================\n",
       "Total params: 317,608,900\n",
       "Trainable params: 317,608,900\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary(model, input_size=(8, 64600))\n",
    "summary(model)\n",
    "# 8 : batch size\n",
    "# 64600 : 4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (ssl_model): SSLModel(\n",
       "    (model): Wav2Vec2Model(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU(approximate='none')\n",
       "          )\n",
       "          (1-4): 4 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU(approximate='none')\n",
       "          )\n",
       "          (5-6): 2 x Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Sequential(\n",
       "              (0): TransposeLast()\n",
       "              (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (2): TransposeLast()\n",
       "            )\n",
       "            (3): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "      (quantizer): GumbelVectorQuantizer(\n",
       "        (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "      )\n",
       "      (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=True)\n",
       "  (selu): SELU(inplace=True)\n",
       "  (loss_CE): CrossEntropyLoss()\n",
       "  (VIB): VIB(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (fc_mu): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (fc_var): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (backend): BackEnd(\n",
       "    (m_frame_level): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (m_utt_level): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (gelu): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 레이어 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "  (1): Dropout(p=0.0, inplace=False)\n",
       "  (2): Sequential(\n",
       "    (0): TransposeLast()\n",
       "    (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): TransposeLast()\n",
       "  )\n",
       "  (3): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ConvFeatureExtractionModel의 마지막 합성곱 레이어\n",
    "model.ssl_model.model.feature_extractor.conv_layers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 확률값 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tensor_input = torch.from_numpy(audio)\n",
    "tensor_input = tensor_input.unsqueeze(0)\n",
    "\n",
    "\n",
    "with torch.no_grad(): # 추론할 때는 가중치를 업데이트할 필요가 없기 때문에 그라디언트 계산 안해도 됨\n",
    "\n",
    "    output = model(tensor_input.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax to convert output to probabilities\n",
    "\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output, dim=1) * 100\n",
    "\n",
    "print(probabilities[0][0]) # spoof probability\n",
    "print(probabilities[0][1]) # bonafide probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_cam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
